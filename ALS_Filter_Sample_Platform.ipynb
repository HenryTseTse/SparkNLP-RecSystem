{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**A Sample ALS Filtering Interface**\n",
        "\n",
        "This is a demostration of how the ALS UI would interact with the user.\n",
        "Disclaimer: Due to GitHub's file size limitations, we were only able to host a smaller dataset. This does not fully demostrate our model that splits as overfitting issues can be caused by splitting a smaller dataset into a training and test set.\n",
        "\n",
        "Please refer to the Collaborative_Filtering.ipynb for the full implementation of Big Data for issues such as train/test dataset and coldStartStrategy that will drop Nulls that are present in the test dataset but not in the train dataset.\n",
        "\n",
        "Please also note that in a complete pipeline, user id information would most likely be captured at the log-in step."
      ],
      "metadata": {
        "id": "mXdP4KNLqRz0"
      },
      "id": "mXdP4KNLqRz0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Setup SparkNLP and PySpark**"
      ],
      "metadata": {
        "id": "2aWDIHhfqtjM"
      },
      "id": "2aWDIHhfqtjM"
    },
    {
      "cell_type": "code",
      "source": [
        "! wget http://setup.johnsnowlabs.com/colab.sh -O - | bash"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8T35goPM3bBz",
        "outputId": "6b72f4f3-ea00-4c37-b3a2-b249b800f063"
      },
      "id": "8T35goPM3bBz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-15 21:42:38--  http://setup.johnsnowlabs.com/colab.sh\n",
            "Resolving setup.johnsnowlabs.com (setup.johnsnowlabs.com)... 51.158.130.125\n",
            "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://setup.johnsnowlabs.com/colab.sh [following]\n",
            "--2022-05-15 21:42:38--  https://setup.johnsnowlabs.com/colab.sh\n",
            "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh [following]\n",
            "--2022-05-15 21:42:38--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1603 (1.6K) [text/plain]\n",
            "Saving to: ‘STDOUT’\n",
            "\n",
            "-                   100%[===================>]   1.57K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-05-15 21:42:38 (38.7 MB/s) - written to stdout [1603/1603]\n",
            "\n",
            "setup Colab for PySpark 3.0.3 and Spark NLP 3.4.4\n",
            "Installing PySpark 3.0.3 and Spark NLP 3.4.4\n",
            "\u001b[K     |████████████████████████████████| 209.1 MB 68 kB/s \n",
            "\u001b[K     |████████████████████████████████| 145 kB 81.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 198 kB 60.2 MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sparknlp.base import *\n",
        "from sparknlp.annotator import *\n",
        "from pyspark.ml import Pipeline\n",
        "import numpy as np\n",
        "from pyspark.ml.linalg import *\n",
        "from pyspark.sql.types import * \n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.ml.feature import *\n",
        "import sparknlp\n",
        "\n",
        "spark = sparknlp.start(gpu=True)\n",
        "\n",
        "print(\"Spark NLP version: \", sparknlp.version())\n",
        "print(\"Apache Spark version: \", spark.version)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjnUFWme3g1q",
        "outputId": "0f4c2f67-5e2a-4f3a-c43e-0e6ae1c26be0"
      },
      "id": "jjnUFWme3g1q",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark NLP version:  3.4.4\n",
            "Apache Spark version:  3.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6de0a89",
      "metadata": {
        "id": "d6de0a89"
      },
      "source": [
        "#**Retrieving Dataset Sample**\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/azraf-a/BERT_SparkNLP_Filter/main/ratings_small.csv -O ratings.csv\n",
        "!wget https://raw.githubusercontent.com/azraf-a/BERT_SparkNLP_Filter/main/movies_small.csv -O movies.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmAU9inn4waq",
        "outputId": "0720500f-e52c-47d6-c23c-42689c666557"
      },
      "id": "KmAU9inn4waq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-15 21:43:42--  https://raw.githubusercontent.com/azraf-a/BERT_SparkNLP_Filter/main/ratings_small.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2483723 (2.4M) [text/plain]\n",
            "Saving to: ‘ratings.csv’\n",
            "\n",
            "ratings.csv         100%[===================>]   2.37M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2022-05-15 21:43:43 (50.1 MB/s) - ‘ratings.csv’ saved [2483723/2483723]\n",
            "\n",
            "--2022-05-15 21:43:43--  https://raw.githubusercontent.com/azraf-a/BERT_SparkNLP_Filter/main/movies_small.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 494431 (483K) [text/plain]\n",
            "Saving to: ‘movies.csv’\n",
            "\n",
            "movies.csv          100%[===================>] 482.84K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2022-05-15 21:43:43 (30.6 MB/s) - ‘movies.csv’ saved [494431/494431]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f95d0d7d",
      "metadata": {
        "id": "f95d0d7d"
      },
      "outputs": [],
      "source": [
        "schema = StructType() \\\n",
        "      .add(\"movieId\",IntegerType(),True) \\\n",
        "      .add(\"imdbId\",StringType(),True) \\\n",
        "      .add(\"tmdbId\",IntegerType(),True)\n",
        "\n",
        "df = spark\\\n",
        ".read\\\n",
        ".option(\"inferSchema\",\"true\")\\\n",
        ".option(\"header\", \"true\")\\\n",
        ".csv(\"ratings.csv\")\n",
        "\n",
        "df=df.drop('timestamp')\n",
        "df=df.drop('genres')\n",
        "\n",
        "df2 = spark\\\n",
        ".read\\\n",
        ".option(\"inferSchema\",\"true\")\\\n",
        ".option(\"header\", \"true\")\\\n",
        ".csv(\"movies.csv\")\n",
        "\n",
        "df4=df.join(df2, ['movieId'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Generating ALS Model**"
      ],
      "metadata": {
        "id": "gru2N-eGq1Zj"
      },
      "id": "gru2N-eGq1Zj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c282ba57",
      "metadata": {
        "id": "c282ba57"
      },
      "outputs": [],
      "source": [
        "#Training the ALS model\n",
        "from pyspark.ml.recommendation import ALS\n",
        "\n",
        "als_model = ALS(userCol='userId',\n",
        "                itemCol='movieId',\n",
        "                nonnegative=True,\n",
        "                regParam=0.1,\n",
        "                rank=10)\n",
        "# rank is the number of latent factors we are choosing\n",
        "\n",
        "recommender = als_model.fit(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05fe6b96",
      "metadata": {
        "id": "05fe6b96"
      },
      "outputs": [],
      "source": [
        "predictions = recommender.transform(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3863e078",
      "metadata": {
        "id": "3863e078"
      },
      "source": [
        "##**User Queries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0433c92",
      "metadata": {
        "id": "d0433c92"
      },
      "outputs": [],
      "source": [
        "#Generate top 10 movie recommendations for each user\n",
        "userRecs = recommender.recommendForAllUsers(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_id = input (\"Please enter your assigned user id ( your assigned number between 1 and 610 ) :\") \n",
        "\n",
        "print(\"Your use id is : \", user_id)\n",
        "print()\n",
        "print(\"Based on your past reviewing history and similar users, we believe you will like: \")\n",
        "rec = [row[0] for row in userRecs.filter(col('userId') == user_id).select('recommendations').collect()]\n",
        "movies = [row[0] for row in rec[0]]\n",
        "for movie in movies:\n",
        "  print(df4.filter(col('movieId') == movie).select('title').collect()[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YItbR_nYJwgo",
        "outputId": "27b4889e-0c06-4b87-fa12-057c8c81a4ab"
      },
      "id": "YItbR_nYJwgo",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter your assigned user id ( your assigned number between 1 and 610 ) :32\n",
            "Your use id is :  32\n",
            "\n",
            "Based on your past reviewing history and similar users, we believe you will like: \n",
            "On the Beach (1959)\n",
            "Saving Face (2004)\n",
            "Victory (a.k.a. Escape to Victory) (1981)\n",
            "Seve (2014)\n",
            "The Big Bus (1976)\n",
            "Grand Day Out with Wallace and Gromit, A (1989)\n",
            "Moby Dick (1956)\n",
            "Holy Mountain, The (Montaña sagrada, La) (1973)\n",
            "Black Mirror: White Christmas (2014)\n",
            "Trial, The (Procès, Le) (1962)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:bigdata]",
      "language": "python",
      "name": "conda-env-bigdata-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "colab": {
      "name": "ALS_Filter_Sample_Platform.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}